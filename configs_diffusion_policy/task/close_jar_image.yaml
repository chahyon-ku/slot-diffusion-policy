# Image dataset

name: close_jar_image

image_shape: &image_shape [3, 128, 128]
shape_meta: &shape_meta
  # acceptable types: rgb, low_dim
  obs:
    image:
      shape: *image_shape
      type: rgb
    agent_pos:
      shape: [8]
      type: low_dim
  action:
    shape: [8]

env_runner:
  # _target_: diffusion_policy.env_runner.pusht_image_runner.PushTImageRunner
  _target_: slot_diffusion_policy.lib.sdp_diffusion_policy.diffusion_policy.env_runner.pusht_image_runner.PushTImageRunner
  n_train: 6
  n_train_vis: 2
  train_start_seed: 0
  n_test: 50
  n_test_vis: 4
  legacy_test: True
  test_start_seed: 100000
  max_steps: 300
  n_obs_steps: ${n_obs_steps}
  n_action_steps: ${n_action_steps}
  fps: 10
  past_action: ${past_action_visible}
  n_envs: null

dataset:
  # _target_: diffusion_policy.dataset.pusht_image_dataset.PushTImageDataset
  _target_: scripts_diffusion_policy.dataset.rlbench_diffusion_dataset.RlbenchImageDataset
  # TODO: Use front_rgb instead of front_depth
  zarr_path: data_zarr/train/close_jar/front_depth/data.zarr
  horizon: ${horizon}
  pad_before: ${eval:'${n_obs_steps}-1'}
  pad_after: ${eval:'${n_action_steps}-1'}
  seed: 42
  val_ratio: 0 # Set this to 0 for now since the eval environment hasn't been set up yet
  max_train_episodes: 90
